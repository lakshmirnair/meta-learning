{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recog_siamese.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmirnair/meta-learning/blob/master/emotion_recog_siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIyth5FPFV8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "!unzip -uq \"/content/drive/My Drive/dataset_zip/dataset.zip\" -d \"/content/drive/My Drive/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4qykYEtOigX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UUscTH3iwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw1EXURsktRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oahc5Suikuzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_image(filename, byteorder='>'):\n",
        "    \n",
        "    #first we read the image, as a raw file to the buffer\n",
        "    with open(filename, 'rb') as f:\n",
        "        buffer = f.read()\n",
        "    \n",
        "    #using regex, we extract the header, width, height and maxval of the image\n",
        "    header, width, height, maxval = re.search(\n",
        "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
        "    \n",
        "    #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array\n",
        "    return np.frombuffer(buffer,\n",
        "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
        "                            count=int(width)*int(height),\n",
        "                            offset=len(header)\n",
        "                            ).reshape((int(height), int(width)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsGPcu6k0Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.open(\"/content/drive/My Drive/data/dataset/s7/1.pgm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhlE-iujlqiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "img = read_image('/content/drive/My Drive/data/dataset/s7/1.pgm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va0V_9rqlyBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIENn09s_VE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1MRV5u5I8ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 2\n",
        "total_sample_size = 128\n",
        "\n",
        "\n",
        "def get_data(size, total_sample_size):\n",
        "    #read the image\n",
        "    image = read_image('/content/drive/My Drive/data/dataset/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
        "    #reduce the size\n",
        "    image = image[::size, ::size]\n",
        "    #get the new size\n",
        "    dim1 = image.shape[0]\n",
        "    dim2 = image.shape[1]\n",
        "\n",
        "    count = 0\n",
        "    \n",
        "    #numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
        "    x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])  # 2 is for pairs\n",
        "    y_genuine = np.zeros([total_sample_size, 1])\n",
        "    \n",
        "    for i in range(7):\n",
        "        for j in range(int(total_sample_size/7)):\n",
        "            ind1 = 0\n",
        "            ind2 = 0\n",
        "            \n",
        "            #read images from same directory (genuine pair)\n",
        "            while ind1 == ind2:\n",
        "                ind1 = np.random.randint(7)\n",
        "                ind2 = np.random.randint(7)\n",
        "            \n",
        "            # read the two images\n",
        "            img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+')\n",
        "            img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+')\n",
        "            \n",
        "            #reduce the size\n",
        "            img1 = img1[::size, ::size]\n",
        "            img2 = img2[::size, ::size]\n",
        "            \n",
        "            #store the images to the initialized numpy array\n",
        "            x_geuine_pair[count, 0, 0, :, :] = img1\n",
        "            x_geuine_pair[count, 1, 0, :, :] = img2\n",
        "            \n",
        "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
        "            y_genuine[count] = 1\n",
        "            count += 1\n",
        "\n",
        "    count = 0\n",
        "    x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
        "    y_imposite = np.zeros([total_sample_size, 1])\n",
        "    \n",
        "    for i in range(int(total_sample_size/7)):\n",
        "        for j in range(7):\n",
        "            \n",
        "            \n",
        "            while True:\n",
        "                ind1 = np.random.randint(7)\n",
        "                ind2 = np.random.randint(7)\n",
        "                if ind1 != ind2:\n",
        "                    break\n",
        "                    \n",
        "            img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "            img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "\n",
        "            img1 = img1[::size, ::size]\n",
        "            img2 = img2[::size, ::size]\n",
        "\n",
        "            x_imposite_pair[count, 0, 0, :, :] = img1\n",
        "            x_imposite_pair[count, 1, 0, :, :] = img2\n",
        "            \n",
        "            y_imposite[count] = 0\n",
        "            count += 1\n",
        "            \n",
        "    #concatenate, genuine pairs and imposite pair to get the whole data\n",
        "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
        "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ9_T9EDKk02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y = get_data(size, total_sample_size)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5hhoyhMrFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C4EAfbyMzcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnNRJi8aM5yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0CVJzVqM8Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_base_network(input_shape):\n",
        "    \n",
        "    seq = Sequential()\n",
        "    \n",
        "    nb_filter = [82, 62]\n",
        "    kernel_size = 3\n",
        "    \n",
        "    \n",
        "    #convolutional layer 1\n",
        "    seq.add(Convolution2D(nb_filter[0], 7, 7, input_shape=input_shape,\n",
        "                          border_mode='valid', dim_ordering='th'))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
        "    #seq.add(Dropout(.25))\n",
        "    \n",
        "    #convolutional layer 2\n",
        "    seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, border_mode='valid', dim_ordering='th'))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(4, 4), dim_ordering='th')) \n",
        "    #seq.add(Dropout(.25))\n",
        "\n",
        "\n",
        "    #flatten \n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(1512, activation='relu'))\n",
        "    seq.add(Dropout(0.525))\n",
        "    seq.add(Dense(512, activation='relu'))\n",
        "    seq.add(Dropout(0.525))\n",
        "    seq.add(Dense(512, activation='relu'))\n",
        "    seq.add(Dense(512, activation='relu'))\n",
        "    seq.add(Dense(512, activation='relu'))\n",
        "    return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5j_sCEkNEnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[2:]\n",
        "img_a = Input(shape=input_dim)\n",
        "img_b = Input(shape=input_dim)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAxMtDxnNJf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_network = build_base_network(input_dim)\n",
        "feat_vecs_a = base_network(img_a)\n",
        "feat_vecs_b = base_network(img_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQUkNlZsNMN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_cXYKJ5NRVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8jU9BaoNWPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "rms = RMSprop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8vwb0pKNYgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input=[img_a, img_b], output=distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5vFAujcNbJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZmdjRWLNeSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=contrastive_loss, optimizer=rms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXhBPV3qNghE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(25):\n",
        "  X,Y= get_data(size, total_sample_size)\n",
        "  img_1 = X[:, 0]\n",
        "  img2 = X[:, 1]\n",
        "  model.train_on_batch([img_1,img2],Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jogk84DPTjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y= get_data(size, total_sample_size)\n",
        "img_1 = X[:, 0]\n",
        "img2 = X[:, 1]\n",
        "model.test_on_batch([img_1,img2],Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI5AJRJVNjYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit([img_1, img2], Y, validation_split=.25,\n",
        "#          batch_size=128, verbose=2, nb_epoch=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4nPZPl7OCg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([X[:, 0], X[:, 1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJFGVhJ0OFU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(predictions, labels):\n",
        "    count=0\n",
        "    threshold=0.01\n",
        "    for i in range(len(labels)):\n",
        "      if predictions[i][0] >= threshold and labels[i][0]==1:\n",
        "        count+=1\n",
        "      elif predictions[i][0] < threshold and labels[i][0]==0:\n",
        "        count+=1\n",
        "    return count/len(labels)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpr0zSihOIXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compute_accuracy(pred, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-J92dWb1Saf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geteachclassimage(i,j,size=2,samplesize=1):\n",
        "  #read the image\n",
        "  image = read_image('/content/drive/My Drive/data/dataset/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  #reduce the size\n",
        "  image = image[::size, ::size]\n",
        "  #get the new size\n",
        "  dim1 = image.shape[0]\n",
        "  dim2 = image.shape[1]\n",
        "  #anger\n",
        "  anger = np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(1) + '/' + str(2) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  anger[0, 0, 0, :, :] = img1\n",
        "  anger[0, 1, 0, :, :] = img2\n",
        "  #disgust\n",
        "  disgust = np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(2) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  disgust[0, 0, 0, :, :] = img1\n",
        "  disgust[0, 1, 0, :, :] = img2\n",
        "\n",
        "  #fear\n",
        "  fear= np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(3) + '/' + str(3) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  fear[0, 0, 0, :, :] = img1\n",
        "  fear[0, 1, 0, :, :] = img2\n",
        "\n",
        "  #happy\n",
        "  happy= np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(4) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  happy[0, 0, 0, :, :] = img1\n",
        "  happy[0, 1, 0, :, :] = img2\n",
        "\n",
        "  #neutral\n",
        "  neutral= np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(5) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  neutral[0, 0, 0, :, :] = img1\n",
        "  neutral[0, 1, 0, :, :] = img2\n",
        "\n",
        "  #sad\n",
        "  sad= np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(6) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  sad[0, 0, 0, :, :] = img1\n",
        "  sad[0, 1, 0, :, :] = img2\n",
        "\n",
        "  #surprise\n",
        "  surprise= np.zeros([samplesize, 2, 1, dim1, dim2])\n",
        "  img1 = read_image('/content/drive/My Drive/data/dataset/s' + str(7) + '/' + str(1) + '.pgm', 'rw+')\n",
        "  img2 = read_image('/content/drive/My Drive/data/dataset/s' + str(i) + '/' + str(j) + '.pgm', 'rw+')\n",
        "            \n",
        "  #reduce the size\n",
        "  img1 = img1[::size, ::size]\n",
        "  img2 = img2[::size, ::size]\n",
        "            \n",
        "  #store the images to the initialized numpy array\n",
        "  surprise[0, 0, 0, :, :] = img1\n",
        "  surprise[0, 1, 0, :, :] = img2\n",
        "\n",
        "  X = np.concatenate([anger, disgust,fear,happy,neutral,sad,surprise], axis=0)/255\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAE4ABONgwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notations={1:\"anger\",2:\"disgust\",3:\"fear\",4:\"happy\",5:\"neutral\",6:\"sad\",7:\"surprise\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVqDYG3DJupo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t=geteachclassimage(1,8)\n",
        "mypredictions=model.predict([t[:, 0], t[:, 1]])\n",
        "minimum_value=mypredictions[0][0]\n",
        "minimum_index=1\n",
        "for i in range(7):\n",
        "  if mypredictions[i][0]<minimum_value:\n",
        "    minimum_value=mypredictions[i][0]\n",
        "    minimum_index=i+1\n",
        "print(notations[minimum_index])    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}